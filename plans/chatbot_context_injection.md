Hereâ€™s a clear Markdown plan describing the update to the chatbot flow to include contextual grounding from the provided hospital schema document:

---

# ğŸ§  Chatbot Context Injection Plan

## ğŸ¯ Objective

Update the existing **chatbot flow** to include **context from the `hospital_schema_guide.md` document** before generating **dynamic SQL queries**.

## ğŸ§© Problem

Currently, the chatbot generates SQL queries without structured awareness of how hospital data is organized. This can lead to:

* Incorrect or inefficient query generation
* Misinterpretation of ambiguous terms (e.g., â€œB+â€ meaning blood group vs. blood inventory)
* Poor schema alignment when users omit table names

## âœ… Solution

Inject the **contents of `hospital_schema_guide.md`** into the chatbotâ€™s reasoning pipeline **before query generation**, so that the LLM:

* Understands available tables, columns, and relationships
* Applies interpretation rules (e.g., where blood group data resides)
* Uses schema-aware logic when constructing SQL

## ğŸ—‚ï¸ Files to Edit (inside `src/` folder)

* `src/components/interface.py` â€“ Modify the logic to:

  * Load the schema context at startup or per session
  * Prepend or embed it in the system message before query generation
* `src/components/interface.py` â€“ Optional edits if UI feedback is added
* At Root `data/hospital_schema_guide.md` â€“ Store this file and read it into the chatbot prompt

## ğŸ§© Context Usage Method

* Load `hospital_schema_guide.md` as a reference chunk
* Inject as part of a **system prompt**, **pre-prompt**, or **context embedding** before every SQL-related user query
* Avoid repeating the document; use caching or memory where possible

## ğŸ’¡ Notes

* Do not alter chatbot personality or other unrelated behaviors
* This does **not** modify the chatbot UI â€“ it only affects backend reasoning
* Ensure schema updates (if any) can be reloaded without restarting the app

---
