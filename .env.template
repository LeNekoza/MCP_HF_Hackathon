# Database Configuration (from neon_config.json)
NEON_HOST=your_neon_host_here
NEON_DATABASE=your_database_name
NEON_USER=your_database_user
NEON_PASSWORD=your_database_password
NEON_PORT=5432
NEON_SSLMODE=require

# Database Upload Settings
CLEAR_EXISTING_DATA=true
BATCH_SIZE=1000
LOG_LEVEL=INFO

# Nebius API Configuration (from nebius_config.json)
NEBIUS_API_KEY=your_nebius_api_key_here
NEBIUS_MODEL=meta-llama/Llama-3.3-70B-Instruct
NEBIUS_MAX_TOKENS=2048
NEBIUS_TEMPERATURE=0.7
NEBIUS_TOP_P=0.9
NEBIUS_TIMEOUT=30

# Application Configuration (from app_config.json)
SERVER_NAME=127.0.0.1
SERVER_PORT=8060
SHARE=false
DEBUG=true
DEFAULT_MODEL=gpt-3.5-turbo
MAX_TOKENS=1000
TEMPERATURE=0.7
APP_TITLE=MCP HF Hackathon
APP_DESCRIPTION=Model Context Protocol Integration with Hugging Face

# Available Models
AVAILABLE_MODELS=gpt-3.5-turbo,gpt-4,claude-3-sonnet,llama-2-7b,mistral-7b,nebius-llama-3.3-70b

# Hugging Face Configuration
HF_API_URL=https://api-inference.huggingface.co/models/
HF_CACHE_DIR=./data/models

# Nebius Model Configuration
NEBIUS_MODEL_NAME=meta-llama/Llama-3.3-70B-Instruct
NEBIUS_API_URL=https://api.studio.nebius.ai/v1
NEBIUS_ENABLED=true

# MCP Configuration
MCP_ENABLED=true
MCP_VERSION=1.0
MCP_PROTOCOL_FEATURES=context_management,model_switching,response_streaming